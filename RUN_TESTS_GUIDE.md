# ðŸ§ª Single Service Test Runner Guide

Cháº¡y test tá»«ng project riÃªng biá»‡t vÃ  hiá»ƒn thá»‹ káº¿t quáº£ real-time trong Grafana dashboard.

## ðŸŽ¯ Features

- âœ… Cháº¡y test cho **má»™t project** hoáº·c **táº¥t cáº£ projects**
- âœ… **Real-time dashboard updates** (Grafana tá»± Ä‘á»™ng refresh)
- âœ… Hiá»ƒn thá»‹ metrics **tá»«ng service** trong dashboard
- âœ… JSON reports cho má»—i service
- âœ… Dá»… sá»­ dá»¥ng - click file .cmd hoáº·c cháº¡y Python script

## ðŸ“‹ Quick Start

### **Option 1: Windows - Sá»­ Dá»¥ng .cmd Files (Dá»… Nháº¥t)**

#### Cháº¡y Test Cho Má»™t Project:
```cmd
# CÃ¡ch 1: Double-click file
run_test.cmd user_service

# CÃ¡ch 2: Command line
cd D:\cnpm\CNPM-3
run_test.cmd product_service
```

#### Cháº¡y Test Táº¥t Cáº£ Projects:
```cmd
# Double-click file
run_all_tests.cmd

# Hoáº·c command line
cd D:\cnpm\CNPM-3
run_all_tests.cmd
```

### **Option 2: Command Line - Python Scripts**

#### Cháº¡y Test Má»™t Project:
```bash
python scripts/run_single_service_test.py D:\cnpm\CNPM-3\DoAnCNPM_Backend user_service
```

#### Cháº¡y Test Táº¥t Cáº£ Projects:
```bash
python scripts/run_all_services_test.py D:\cnpm\CNPM-3\DoAnCNPM_Backend
```

## ðŸŽ® CÃ¡c Project CÃ³ Sáºµn

| Service | Location |
|---------|----------|
| **user_service** | DoAnCNPM_Backend/user_service |
| **product_service** | DoAnCNPM_Backend/product_service |
| **drone_service** | DoAnCNPM_Backend/drone_service |
| **order_service** | DoAnCNPM_Backend/order_service |
| **payment_service** | DoAnCNPM_Backend/payment_service |
| **restaurant-service** | DoAnCNPM_Backend/restaurant-service |

## ðŸ“Š Grafana Dashboard Integration

### **CÃ¡ch Hoáº¡t Äá»™ng:**

```
1. Cháº¡y: run_test.cmd user_service
   â†“
2. Script thá»±c thi: mvn test -q
   â†“
3. Parse: TEST-*.xml reports
   â†“
4. Update: monitoring/metrics/test_metrics.txt
   â†“
5. Prometheus scrape metrics (sau ~30s)
   â†“
6. Grafana display latest data
   â†“
Dashboard auto-refresh: http://localhost:3001
```

### **Dashboard Panels ÄÆ°á»£c Update:**

1. **Test Results by Service** (Table)
   - Columns: Service, Passed, Failed, Total
   - Auto-filter theo service label

2. **Success Rate by Service %** (Gauge)
   - Shows pass rate per service
   - Color coded: Green (>95%), Yellow (>80%), Red (<80%)

3. **Test Execution Time** (Time Series)
   - Shows execution time trend per service

4. **Test Rate Trends** (Line Chart)
   - Total/Pass/Fail counts over time

## ðŸ“ˆ Metrics Generated

### **Per-Service Metrics:**
```promql
test_count_by_service{service="user_service"}
test_pass_count_by_service{service="user_service"}
test_fail_count_by_service{service="user_service"}
test_pass_rate_by_service{service="user_service"}
test_execution_time_by_service{service="user_service"}
```

### **Summary Metrics:**
```promql
test_count_total              # Total all tests
test_pass_count              # Total passed
test_fail_count              # Total failed
test_pass_rate_percent       # Overall pass rate
test_execution_time_seconds  # Total time
```

## ðŸ“ Output Files

### **After running tests:**

```
monitoring/metrics/
â”œâ”€â”€ test_metrics.txt                    # Prometheus format (Grafana reads this)
â”œâ”€â”€ test_report_user_service.json       # Individual service report
â”œâ”€â”€ test_report_product_service.json
â”œâ”€â”€ test_report_drone_service.json
â””â”€â”€ ... (má»™t file cho má»—i service)
```

### **Example test_report_user_service.json:**
```json
{
  "service": "user_service",
  "timestamp": "2025-11-26T10:30:45.123456",
  "metrics": {
    "total_tests": 48,
    "passed_tests": 48,
    "failed_tests": 0,
    "execution_time_seconds": 12.45,
    "pass_rate_percent": 100.0,
    "status": "PASS"
  }
}
```

## ðŸ”„ Workflow Example

### **Scenario: Cháº¡y test tá»«ng service**

```bash
# Terminal 1 - Cháº¡y Prometheus
prometheus --config.file=monitoring/prometheus.yml

# Terminal 2 - Cháº¡y Metrics Server
python monitoring/metrics-server.py

# Terminal 3 - Docker Grafana
docker-compose up grafana

# Terminal 4 - Cháº¡y tests tuáº§n tá»±
cd D:\cnpm\CNPM-3

# Test user_service
run_test.cmd user_service
# âœ“ PASS: 48 tests passed

# Test product_service  
run_test.cmd product_service
# âœ“ PASS: 27 tests passed

# Test order_service
run_test.cmd order_service
# âœ“ PASS: 4 tests passed

# Xem Dashboard
# Open: http://localhost:3001
# â†’ Báº£ng "Test Results by Service" hiá»ƒn thá»‹ 3 services vá»«a cháº¡y
```

## âš™ï¸ Configuration

### **Edit Service List** (scripts/run_all_services_test.py)
```python
self.services = [
    'user_service',
    'product_service',
    'drone_service',
    'order_service',
    'payment_service',
    'restaurant-service',
    # ThÃªm project má»›i á»Ÿ Ä‘Ã¢y
]
```

### **Edit Paths** (run_test.cmd)
```cmd
set "BACKEND_PATH=D:\cnpm\CNPM-3\DoAnCNPM_Backend"
set "SCRIPT_PATH=D:\cnpm\CNPM-3\scripts\run_single_service_test.py"
```

## ðŸ› Troubleshooting

### **Q: Dashboard khÃ´ng update sau khi cháº¡y test?**
**A:**
1. Check metrics file: `monitoring/metrics/test_metrics.txt`
2. Check Prometheus targets: http://localhost:9090/targets
3. Wait 30 seconds (Prometheus scrape interval)
4. Refresh Grafana: http://localhost:3001 (F5)

### **Q: "Maven not found" error?**
**A:**
- Cáº§n cÃ³ Maven installed: https://maven.apache.org/download.cgi
- ThÃªm Maven vÃ o PATH

### **Q: Metrics file rá»—ng?**
**A:**
```bash
# Check test reports exist
dir D:\cnpm\CNPM-3\DoAnCNPM_Backend\user_service\target\surefire-reports\

# If empty, run tests manually
cd D:\cnpm\CNPM-3\DoAnCNPM_Backend\user_service
mvn test
```

### **Q: CÃ¡ch xem logs?**
**A:**
```bash
# Xem JSON report
type monitoring\metrics\test_report_user_service.json

# Xem metrics raw
type monitoring\metrics\test_metrics.txt

# Xem Prometheus logs
docker-compose logs prometheus

# Xem Grafana logs
docker-compose logs grafana
```

## ðŸ“š File Structure

```
D:\cnpm\CNPM-3\
â”œâ”€â”€ run_test.cmd                          # â† Click Ä‘á»ƒ cháº¡y 1 service
â”œâ”€â”€ run_all_tests.cmd                     # â† Click Ä‘á»ƒ cháº¡y táº¥t cáº£
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_single_service_test.py        # Python script for 1 service
â”‚   â””â”€â”€ run_all_services_test.py          # Python script for all services
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ metrics-server.py                 # Expose metrics endpoint
â”‚   â”œâ”€â”€ prometheus.yml                    # Prometheus config
â”‚   â””â”€â”€ metrics/
â”‚       â”œâ”€â”€ test_metrics.txt              # Prometheus format
â”‚       â””â”€â”€ test_report_*.json            # Individual reports
â””â”€â”€ DoAnCNPM_Backend/
    â”œâ”€â”€ user_service/
    â”œâ”€â”€ product_service/
    â”œâ”€â”€ drone_service/
    â”œâ”€â”€ order_service/
    â”œâ”€â”€ payment_service/
    â””â”€â”€ restaurant-service/
```

## ðŸŽ¯ Best Practices

âœ… **Do:**
- Cháº¡y metrics-server & Prometheus trÆ°á»›c khi test
- Cháº¡y tá»«ng service má»™t láº§n Ä‘á»ƒ verify
- Check dashboard sau má»—i batch test
- Commit metrics reports Ä‘á»ƒ track history

âŒ **Don't:**
- Cháº¡y tests trÆ°á»›c khi metrics-server ready
- Modify test_metrics.txt manually
- Delete surefire-reports folders
- Run multiple tests cÃ¹ng lÃºc (gÃ¢y race condition)

## ðŸš€ Next Steps

1. **Setup Metrics Infrastructure:**
   ```bash
   docker-compose up -d
   ```

2. **Run Single Service Test:**
   ```cmd
   run_test.cmd user_service
   ```

3. **View Dashboard:**
   - Open: http://localhost:3001
   - Login: admin/admin
   - Go to: Services Dashboard

4. **Run All Tests:**
   ```cmd
   run_all_tests.cmd
   ```

5. **Monitor Progress:**
   - Watch test output in terminal
   - Watch dashboard update in real-time
   - Check JSON reports for details

---

**Version**: 1.0  
**Last Updated**: 2025-11-26  
**Author**: CNPM Team
